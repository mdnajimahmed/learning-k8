`Pod design (20%)`
# Content 01
https://github.com/dgkanatsios/CKAD-exercises/blob/main/c.pod_design.md

- Create 3 pods with names nginx1,nginx2,nginx3. All of them should have the label app=v1
    - for i in `seq 1 3`;do kubectl run nginx$i --image=nginx -l app=v1; done;
    - for i in `seq 1 3`;do kubectl run nginx$i --image=nginx --labels=app=v1; done;
    - kubectl get pods --show-labels

- Show all labels of the pods
    - kubectl get pods --show-labels

- Change the labels of pod 'nginx2' to be app=v2
    - kubectl label pod nginx2 app=v2 --overwrite

- Get the label 'app' for the pods (show a column with APP labels)
    - [VVI] kubectl get po -L app
- Get only the 'app=v2' pods
    -  kubectl get pods -l app=v2 --show-labels
    -  kubectl get pods -l app=v2 -L app

- Add a new label tier=web to all pods having 'app=v2' or 'app=v1' labels
    - kubectl label pods -l='app in (v1,v2)' tier=web

- Add an annotation 'owner: marketing' to all pods having 'app=v2' label
    - kubectl label pod -l app=v2 owner=marketing
    - kubectl get pods -l app=v2 --show-labels
- Remove the 'app' label from the pods we created before
    - kubectl label pod -l app app-

- Create a pod that will be deployed to a Node that has the label 'accelerator=nvidia-tesla-p100'
    - kubectl label node minikube-m02 accelerator=nvidia-tesla-p100
    - kubectl get nodes -L accelerator
    - kubectl apply -f 022.yml 
    - https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes/ `This is a intutive straightforward solution (Assign Pods to Nodes)`
    - kubectl get pods -o wide

- Annotate pods nginx1, nginx2, nginx3 with "description='my description'" value `because of the space we need to put it inside double quote`
    - kubectl annotate pod nginx{1..3} description='my description'
- Check the annotations for pod nginx1
    - kubectl annotate pod nginx1 --list
- Remove the annotations for these three pods
    - kubectl annotate pod nginx{1..3} description-
    - kubectl annotate pod nginx{1..3} --list
- Remove these pods to have a clean state in your cluster
    - kubectl delete pod nginx{1..3}
- Create a deployment with image nginx:1.18.0, called nginx, having 2 replicas, defining port 80 as the port that this container exposes (don't create a service for this deployment)
    - kubectl create deploy nginx --image=nginx:1.18.0 --port=80 --replicas=2
- View the YAML of this deployment
    - kubectl get deploy nginx -o yaml
- View the YAML of the replica set that was created by this deployment
    - `Find the labels inside the Pod Template` kubectl describe deployment nginx  `app=nginx`
    - kubectl get rs -l app=nginx 
    - kubectl get rs nginx-6dc6fccf5  -o yaml
- Get the YAML for one of the pods
    - kubectl get pods -l app=nginx
    - kubectl get pod nginx-6dc6fccf5-9jknk -o yaml
- Check how the deployment rollout is going
    - kubectl rollout status deploy nginx

- Update the nginx image to nginx:1.19.8
    - kubectl rollout history deploy nginx
    - kubectl annotate deployment nginx kubernetes.io/change-cause="initial deployment"
    - kubectl rollout history deploy nginx
    - kubectl set image deploy nginx nginx=nginx:1.19.8
    - kubectl annotate deployment nginx kubernetes.io/change-cause="update nginx to 1.19.8"

- Check the rollout history and confirm that the replicas are OK
    - kubectl rollout history deploy nginx `see the latest deployment change`
    - kubectl rollout status deploy nginx `see the latest deployment status`
- Undo the latest rollout and verify that new pods have the old image (nginx:1.18.0)
    - kubectl rollout undo deploy nginx
    - kubectl rollout history deploy nginx
    - kubectl rollout status deploy nginx
    - kubectl describe deploy nginx | grep -i 'image' .`Image:        nginx:1.18.0`
    - kubectl describe pod nginx-6dc6fccf5-fgft5 | grep -i 'image' `Image:          nginx:1.18.0`
- Do an on purpose update of the deployment with a wrong image nginx:100.200-vague-image
    - set image deploy nginx nginx=nginx:100.200-vague-image
    - kubectl annotate deployment nginx kubernetes.io/change-cause="setting vague nginx image"

- Verify that something's wrong with the rollout
    - kubectl rollout status deploy nginx `its stuck`
    - kubectl get pods `look for 'ErrImagePull' or 'ImagePullBackOff'`
- Return the deployment to the second revision (number 2) and verify the image is nginx:1.19.8
    - kubectl rollout history deploy nginx
    - kubectl rollout undo deploy nginx --to-revision=2
    - kubectl describe deploy nginx | grep -i 'image' `Image:        nginx:1.19.8`
    - kubectl describe pods nginx-5d5fcfcd68-6nql2 | grep -i 'image' `Image:          nginx:1.19.8`
- Check the details of the fourth revision (number 4)
    - [VVI] kubectl rollout history deploy nginx --revision=4
- Scale the deployment to 5 replicas
    - kubectl scale deploy nginx --replicas=3
- Autoscale the deployment, pods between 5 and 10, targetting CPU utilization at 80%
    - kubectl autoscale deployment nginx --min=5 --max=10 --cpu-percent=80
- Pause the rollout of the deployment
    - kubectl rollout pause deploy nginx
- Update the image to nginx:1.19.9 and check that there's nothing going on, since we paused the rollout
    - kubectl set image deploy nginx nginx=nginx:1.19.9
    - kubectl describe deploy nginx  `check the event section, no decent events`
- Resume the rollout and check that the nginx:1.19.9 image has been applied
    - kubectl rollout resume deploy nginx
    - kubectl describe deploy nginx
- Delete the deployment and the horizontal pod autoscaler you created
    - kubectl rollout history deploy nginx
- Implement canary deployment by running two instances of nginx marked as version=v1 and version=v2 so that the load is balanced at 75%-25% ratio
    - Goal : We need total 4 pods running, 3 with label version=v1(nginx:1.18.0) and 1 with label version=v2(nginx:1.19.9).
    - A service needs to forward traffic to all those 4 pods hence, all 4 should have a common label, e.g `service:canary`
    - Steps:
        - Run 4 pods with label `service=canary`
            - kubectl create deploy nginxv1 --image=nginx:1.18.0 --replicas=4 --port=80
            - kubectl get pods --show-labels
            - kubectl label pod -l app service=canary
        - Create a service that uses selector service=canary
            - kubectl expose deployment nginxv1 --selector=service=canary --name=canary -l service=canary
        - Change image of 1 pod to nginx:1.19.9 and update the label of the pod from version=v1 to version=v2
            - kubectl create deploy nginxv2 --image=nginx:1.19.9 --replicas=1 --port=80
            - kubectl label pod -l app service=canary
            - kubectl scale deploy nginxv1 --replcias=3
            - Gradually we can run `kubectl scale deploy nginxv2 --replicas=2 AND kubectl scale deploy nginxv1 --replicas=2`
            - kubectl delete deploy nginxv{1..2}
            - kubectl delete svc canary
        

- Create a job named pi with image perl:5.34 that runs the command with arguments "perl -Mbignum=bpi -wle 'print bpi(2000)'"
    - kubectl create job pi --image=perl:5.34  -- perl -Mbignum=bpi -wle 'print bpi(2000)'
- Wait till it's done, get the output
    - kubectl logs pi-mnkkt
- Create a job with the image busybox that executes the command 'echo hello;sleep 30;echo world'
    - kubectl logs busybox-ksm7q -f
- Follow the logs for the pod (you'll wait for 30 seconds)
    - kubectl logs busybox-ksm7q -f
- See the status of the job, describe it and see the logs
    - kubectl describe job busybox
- Delete the job
    - kubectl delete job busybox
- Create a job but ensure that it will be automatically terminated by kubernetes if it takes more than 30 seconds to execute
    -  kubectl create job timedjob --image=busybox --dry-run=client -o yaml -- sleep 40 > 023.yml `.spec.completions=5`
    - `023.yml`  kubectl apply -f 023.yml
    - kubectl describe job timedjob `check the events section`
- Create the same job, make it run 5 times, one after the other. Verify its status and delete it
    - `024.yml ` kubectl apply -f 024.yml 
    - kubectl get job jobwith5tasks
    - kubectl describe job jobwith5tasks `check the events section`
- Create the same job, but make it run 5 parallel times
    - `025.yml` kubectl apply -f 025.yml

- Create a cron job with image busybox that runs on a schedule of "*/1 * * * *" and writes 'date; echo Hello from the Kubernetes cluster' to standard output
    - kubectl create cj busyboxcj --schedule='*/1 * * * *' --image=busybox -- sh -c 'date; echo Hello from the Kubernetes cluster' 
- See its logs and delete it
    - kubectl get pods --show-labels
    - kubectl logs busyboxcj-27776510-vbhxm
- Create the same cron job again, and watch the status. Once it ran, check which job ran by the created cron job. Check the log, and delete the cron job
    - [VVI] kubectl get jobs --watch `cron job creates job, which further creates pod`
- Create a cron job with image busybox that runs every minute and writes 'date; echo Hello from the Kubernetes cluster' to standard output. The cron job should be terminated if it takes more than 17 seconds to start execution after its scheduled time (i.e. the job missed its scheduled time). Determine the number of successful executions the CronJob will keep in its history.
    - `026.yml` kubectl apply -f 026.yml
    - kubectl describe cj busyboxcjtimed and verify
    ```
    Successful Job History Limit:  10
Failed Job History Limit:      10
    ```

- Create a cron job with image busybox that runs every minute and writes 'date; echo Hello from the Kubernetes cluster' to standard output. The cron job should be terminated if it successfully starts but takes more than 12 seconds to complete execution.
    - `027.yml` kubectl apply -f 027.yml

# Content 02
- Create three different Pods with the names frontend, backend and database that use the image nginx.
    - for name in frontend backend database; do kubectl run $name --image=nginx; done 
- Declare labels for those Pods as follows:
```
frontend: env=prod,team=shiny
backend: env=prod, team=legacy, app=v1.2.4
database: env=prod, team=storage
```
    - kubectl label pod frontend env=prod team=shiny
    - kubectl label pod backend env=prod team=legacy app=v1.2.4
    - kubectl label pod database env=prod team=storage
- Declare annotations for those Pods as follows:
```
frontend: contact=John Doe, commit=2d3mg3
backend: contact=Mary Harris
```
    - kubectl annotate pod frontend contact='John Doe' commit=2d3mg3
    - kubectl annotate pod frontend --list
    - kubectl annotate pod backend contact='Mary Harris'
    - kubectl annotate pod backend --list
- Render the list of all Pods and their labels.
    - kubectl get pods --show-labels
- Use label selectors on the command line to query for all production Pods that belong to the teams shiny and legacy.
    - kubectl get pod -l=env=prod,'team in (shiny,legacy)' --show-labels
- Remove the label env from the backend Pod and rerun the selection.
    - kubectl label pod backend env-
    - kubectl get pods -L env
- Render the surrounding 3 lines of YAML of all Pods that have annotations.
    - [VVI] kubectl get pods -o yaml | grep -C 3 'annotations:'