# Configuration:
- Setup
    - kubectl run bb --image=busybox --restart=Never -- sleep 300
    - kubectl exec -it bb sh
    - kubectl run bb --image=busybox --restart=Never -it --rm -- sh # for testing
  
  - Three ways we can make configMapAvailable to a pod
    1. Mount full configmap.
    ```
    envFrom:
      - secretRef:
          name: course03-practice-secret
      - configMapRef:
          name: course03-practice-cm
    ````
    2. Select a subset from the configmap
    ```
     env:
        # Define the environment variable
        - name: PLAYER_INITIAL_LIVES # Notice that the case is different here
                                     # from the key name in the ConfigMap.
          valueFrom:
            configMapKeyRef:
              name: game-demo           # The ConfigMap this value comes from.
              key: player_initial_lives # The key to fetch.
    ```
    3. Mount as a file:
    ```
    In the container 
    volumeMounts:
      - name: config
        mountPath: "/config"
        readOnly: true
    In the pod spec define the mapping 
    volumes:
    # You set volumes at the Pod level, then mount them into containers inside that Pod
    - name: config
      configMap:
        # Provide the name of the ConfigMap you want to mount.
        name: game-demo
        # An array of keys from the ConfigMap to create as files
        items:
        - key: "game.properties"
          path: "game.properties"
        - key: "user-interface.properties"
          path: "user-interface.properties"
    ```
    And then inside pod, cat /config/game.properties. If you omit the items array entirely, every key in the ConfigMap becomes a file with the same name as the key, and you get 4 files.

- Secrets are decoded when passed to pod as a file or env variable.
- Extract secret value from kubernetes
    - `kubectl get secret course03-practice-secret -o yaml ` - will show the secret in base64 , just get it from there and decode base64

# Task 01: (# property-like keys; each key maps to a simple value)
- Create a configmap using property like keys
    - kubectl create cm cmfl --from-literal=key1=val1 --from-literal=key2=val2
    ```
    kubectl get cm cmfl -o yaml                                             
    apiVersion: v1
    data:
    key1: val1
    key2: val2
    kind: ConfigMap
    metadata:
    creationTimestamp: "2022-10-20T12:24:46Z"
    name: cmfl
    namespace: default
    resourceVersion: "498273"
    uid: 9671aee4-1be4-47e5-ba6c-c1e04df6e506
    ```
    - Mount cmfl as environment variable and verify
        ```
        apiVersion: v1
        kind: Pod
        metadata:
        labels:
            run: bb
        name: bb
        spec:
        containers:
        - args:
            - sleep
            - "300"
            image: busybox
            name: bb
            envFrom:
            - configMapRef:
                name: cmfl
        dnsPolicy: ClusterFirst
        restartPolicy: Never
        ```
        - kubectl apply -f the above yaml.
        - kubectl run bb --image=busybox --restart=Never -o yaml --dry-run=client -- sleep 300 
        - kubectl exec -it bb -- env | grep key
    - Mount cmfl as file and verify
        ```
        apiVersion: v1
        kind: Pod
        metadata:
        name: bb2
        spec:
        containers:
            - name: bb2
            image: busybox
            command: [ "/bin/sh", "-c", "sleep 300" ]
            volumeMounts:
            - name: config-volume
                mountPath: /etc/config
        volumes:
            - name: config-volume
              configMap:
                name: cmfl
        restartPolicy: Never
        ```
        - create the pod using the above yaml.
        - kubectl exec -it bb2 -- ls /etc/config
        - kubectl exec -it bb2 -- cat /etc/config/key1
        - kubectl exec -it bb2 -- cat /etc/config/key2
        ```
        apiVersion: v1
        kind: Pod
        metadata:
        name: bb2
        spec:
        containers:
            - name: bb2
            image: busybox
            command: [ "/bin/sh", "-c", "sleep 300" ]
            volumeMounts:
            - name: config-volume
                mountPath: /etc/config
        volumes:
            - name: config-volume
              configMap:
                name: cmfl
        restartPolicy: Never
        ```

        - We can also pick a portion of the config 
        ```
        apiVersion: v1
        kind: Pod
        metadata:
        name: bb3
        spec:
        containers:
            - name: bb3
            image: busybox
            command: [ "/bin/sh", "-c", "sleep 300" ]
            volumeMounts:
            - name: config-volume
                mountPath: /etc/config
        volumes:
            - name: config-volume
            configMap:
                name: cmfl
                items:
                - key: "key1"
                  path: key1
        restartPolicy: Never
        ```
        - create the pod using the above yaml.
        - kubectl exec -it bb3 -- ls /etc/config
        - kubectl exec -it bb3 -- cat /etc/config/key1
        - kubectl exec -it bb3 -- cat /etc/config/key2
- Same experiments can be repeated using ----from-env-file
    - kubectl create configMap CONFIG_MAP_NAME --from-env-file=app_config.txt (property-like keys)
- Conclusion on property-like keys
    - We can use --from-literal multiple times
    - We can use --from-env-file
    - We can mount as environment variable (even a subset or the full config map)
    - We can mount as file (even a subset using configmap->name->items->[ key,path ] or the full config map -- just ignore the items)
# Task 02: (#file-like keys)
- Note:
    - The idea is that you have a properties file and you want to have that `file` to be mounted inside your pod so that you can read the environment variables from that file during runtime. Hence, we can not use envFrom and choose key and volume mount is the only option.
   
- Setup:
    - kubectl create cm cmff --from-file=data.properties
    - kubectl get cm cmff -o yaml
    ```apiVersion: v1
    data:
    data.properties: |
        from_file_1=data_1
        from_file_2=data_2
    kind: ConfigMap
    metadata:
    creationTimestamp: "2022-10-21T00:41:02Z"
    name: cmff
    namespace: default
    resourceVersion: "529675"
    uid: 0f468b3b-a0d9-4fe0-85b7-aaf22327b257
    ```
    - Create the following pod
    ```
    apiVersion: v1
    kind: Pod
    metadata:
    name: bb4
    spec:
    containers:
        - name: bb4
        image: busybox
        command: [ "/bin/sh", "-c", "sleep 300" ]
        volumeMounts:
        - name: config-volume
            mountPath: /etc/config
    volumes:
        - name: config-volume
        configMap:
            name: cmff
    restartPolicy: Never
    ```
    - kubectl exec -it bb4 -- ls /etc/config
    - kubectl exec -it bb4 -- cat /etc/config/data.properties
- [VVI] I still need to figure out if there is any way to mount a single key from the file-like keys and mount it as environment variable, I guess it's called file-like keys for a reason.
- You can combine property-like keys and file-like keys in the same ConfigManager.
- Volume mount comparison for property-like keys and file-like keys
```
- All the property-like keys are file
volumes:
    - name: config-volume
      configMap:
        name: cmfl
    ---
- Only the selected keys from the property-like keys are file
volumes:
    - name: config-volume
      configMap:
        name: cmfl
        items:
        - key: "key1"
          path: key1
    ---
    volumes:
    - name: config-volume
      configMap:
        name: cmff
- The properties file itself is mounted (As there is no property like keys and only one file line keys)
```
- Summary for volume mount : Each key is a file in the pod, filename is the name of the key.
- Updating configmap updates the view inside the pod `eventually not in real time`, a control loop periodically syncs config map and pods view, to make it more efficient we can declare immutable config map `immutable: true`. Details in the documentation `Mounted ConfigMaps are updated automatically` and `Immutable ConfigMaps`.
- A common exam scenario is to change the value of an environment variable, the right strategy is to dump the yaml for the pod, delete the pod, make necessary changes and re-create the pod. Pretty much same for other k8s resources.

# Secret
- kubectl create secret generic db-access --from-file=secret.properties
```
kubectl get secret db-access -o yaml
apiVersion: v1
data:
  secret.properties: dXNlcm5hbWU9bmFqaW0KcGFzc3dvcmQ9YWhtZWQ=
kind: Secret
metadata:
  creationTimestamp: "2022-10-21T05:10:58Z"
  name: db-access
  namespace: default
  resourceVersion: "541190"
  uid: 0e532f82-7a85-41b9-b33c-9c3c443f5213
type: Opaque
```
- kubectl create secret generic db-access --from-env-file=secret.properties
```
kubectl get secret db-access -o yaml
apiVersion: v1
data:
  password: YWhtZWQ=
  username: bmFqaW0=
kind: Secret
metadata:
  creationTimestamp: "2022-10-21T05:12:03Z"
  name: db-access
  namespace: default
  resourceVersion: "541238"
  uid: b38a68cc-f477-4806-8e76-39b6f612259d
type: Opaque
```
- kubectl create secret generic db-access --from-env-file=secret.properties
- kubectl apply -f 4_task_05.yml
- kubectl exec bb5 -- ls /etc/config
- kubectl exec bb5 -- cat /etc/config/secret.properties
- Declarative approach 
```
apiVersion: v1
data:
  username: YWRtaW4=
  password: MWYyZDFlMmU2N2Rm
kind: Secret
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: { ... }
  creationTimestamp: 2020-01-22T18:41:56Z
  name: mysecret
  namespace: default
  resourceVersion: "164619"
  uid: cfee02d6-c137-11e5-8d73-42010af00002
type: Opaque
```
*Watch carefully, in the declarative approach we use a k8s spec file which is a k8s object, hence the secret needs to be base64 encoded.*
- Conclusion:
    - The API is same as configmap except the data is base64 encrypted when it enters into k8s system.
    - On the file, it's not encoded, its encoded only in the k8s system.
    - When they are passed to pod (either as env or as file) they are decrypted back.

# Security Context:
- A bit advanced and more related to sys admin
- Be careful about where to declare the security context - at pod level or at container level 
- [VVI] `allowPrivilegeEscalation`: Controls whether a process can gain more privileges than its parent process. This bool directly controls whether the no_new_privs flag gets set on the container process. allowPrivilegeEscalation is always true when the container:is run as privileged, or has CAP_SYS_ADMIN.
- [VVI] `readOnlyRootFilesystem`: Mounts the container's root filesystem as read-only. `kubectl exec sec-ctx -- bash -c "echo 'Hello Najim' > /usr/share/nginx/html/index.html"` - I can write , but with readOnlyRootFilesystem: true we should not be. Lesson learned, with this flag, nginx can not start, because it needs to write something.

# Service account:
- We can not edit the service account of a pod. We will have to delete the pod and recreate the pod.

# Pod to Node relationships:

- Assigning Pods to Nodes :
    You can use any of the following methods to choose where Kubernetes schedules specific Pods:
    - nodeSelector field matching against node labels (The recommended way), however we can not and/or/in/not type advanced selection.For that we need affinity.
        ```
        nodeSelector:
            accelerator: nvidia-tesla-p100
        ```
    - Affinity and anti-affinity (requiredDuringSchedulingIgnoredDuringExecution,preferredDuringSchedulingIgnoredDuringExecution)
        - Node affinity: Node affinity is a property of Pods that attracts them to a set of nodes (either as a preference or a hard requirement).
        ```
        affinity:
        nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
            - key: topology.kubernetes.io/zone
                operator: In
                values:
                - antarctica-east1
                - antarctica-west1
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 1
            preference:
            matchExpressions:
            - key: another-node-label-key
                operator: In
                values:
                - another-node-label-value
        ```
        - Node anti-affinity: Node anti-affinity aka Taints allow a node to repel a set of pods.
        - nodeName : Hardcoded binding
    ```
    - nodeName: kube-01
   
   ```
    - Pod topology spread constraints

# Taints and Tolerations
- kubectl taint nodes node1 key1=value1:NoSchedule - `The taint has key key1, value value1, and taint effect NoSchedule. This means that no pod will be able to schedule onto node1 unless it has a matching toleration.`
- kubectl taint nodes node1 key1=value1:PreferNoSchedule - `This is a "preference" or "soft" version of NoSchedule -- the system will try to avoid placing a pod that does not tolerate the taint on the node, but it is not required`
- kubectl taint nodes node1 key1=value1:NoExecute - `The pod will be evicted from the node (if it is already running on the node), and will not be scheduled onto the node (if it is not yet running on the node).`
- kubectl taint nodes node1 key1=value1:NoSchedule-
- Operators: Exists,Equal
- Taints by default repeals unless there is a toleration.
- Example:
    - kubectl get pods
    - kubectl run ng --image=nginx
    - kubectl get nodes
    - kubectl taint nodes minikube key=m4large:NoExecute
    - kubectl taint nodes minikube key=m4large:NoExecute-
    - kubectl taint nodes minikube ec2=m4large:NoExecute hdd=gen1:NoExecute
    - kubectl taint nodes minikube ec2- hdd-
    - kubectl describe node minikube | grep -i 'taint' -A2
    - kubectl run ng --image=nginx -o yaml --dry-run=client
    - kubectl apply -f taint.yml
    ```
    apiVersion: v1
    kind: Pod
    metadata:
    labels:
        run: ng1
    name: ng1
    spec:
    containers:
    - image: nginx
        name: ng1
    dnsPolicy: ClusterFirst
    restartPolicy: Always
    tolerations:
    - key: "ec2"
        operator: "Equal"
        value: "m4large"  # Allow this pod to go to ec2=m4large, however it's not gurranted , effectively what I am telling here is `I don't mind if the pod goes to ec2=m4large`
        effect: "NoExecute"
    - key: "hdd" # Effectively what I am telling here is `I don't mind if the pod goes to an instance that is running on hdd`
        operator: "Exists" 
        effect: "NoExecute"
    ```
    - kubectl get pods - working fine
    - kubectl taint nodes minikube ec2=m4large:NoExecute- hdd=gen1:NoExecute-
    - kubectl describe node minikube | grep -i 'taint' -A2

# Always
- Delete the k8s object and create a new one especially for pods.
```
tolerations:
- key: "key1"
  operator: "Equal"
  value: "value1"
  effect: "NoSchedule"
```

# Other
Define the key to use when creating a ConfigMap from a file
- kubectl create configmap game-config-3 --from-file=<my-key-name>=<path-to-file>

```
apiVersion: v1
kind: Pod
metadata:
  name: memory-demo-2
  namespace: mem-example
spec:
  containers:
  - name: memory-demo-2-ctr
    image: polinux/stress
    resources:
      requests:
        memory: "50Mi"
      limits:
        memory: "100Mi"
    command: ["stress"]
    args: ["--vm", "1", "--vm-bytes", "250M", "--vm-hang", "1"]
```
 - kubectl apply -f https://k8s.io/examples/pods/resource/memory-request-limit-2.yaml --namespace=mem-example
 - kubectl get pod memory-demo-2 --namespace=mem-example
 ```
 NAME            READY     STATUS      RESTARTS   AGE
memory-demo-2   0/1       OOMKilled   1          24s
 ```
 - `OOMKilled` means memory the pod was killed by kuber
 - If the cluster does not have enough resource to schedule POD, the it will remain in pending status.
 - kubectl describe pod memory-demo-3 --namespace=mem-example
 ```
NAME            READY     STATUS    RESTARTS   AGE
memory-demo-3   0/1       Pending   0          25s
 ```
- And also, we can check the events section of the pod.
Events:
  ...  Reason            Message
       ------            -------
  ...  FailedScheduling  No nodes are available that match all of the following predicates:: Insufficient memory (3).
- Memory units - `E, P, T, G, M, K, Ei, Pi, Ti, Gi, Mi, Ki` - M is megabyte, Mi is mebibyte.
- Limits and requests for memory are measured in bytes. You can express memory as a plain integer or as a fixed-point integer using one of these suffixes: E, P, T, G, M, K. You can also use the power-of-two equivalents: Ei, Pi, Ti, Gi, Mi, Ki. For example, the following represent roughly the same value:
- Fractional values are allowed. A Container that requests 0.5 CPU is guaranteed half as much CPU as a Container that requests 1 CPU. You can use the suffix m to mean milli. For example 100m CPU, 100 milliCPU, and 0.1 CPU are all the same. Precision finer than 1m is not allowed.
- CPU is always requested as an absolute quantity, never as a relative quantity; 0.1 is the same amount of CPU on a single-core, dual-core, or 48-core machine
- cpu: "100" means give me 100 cpus, cpu: ".5" - means give me half of a single cpu.
- 1 cpu =  1.0 or 1000m 
- 1000m (milicores) = 1 core = 1 vCPU = 1 AWS vCPU = 1 GCP Core.
- 100m (milicores) = 0.1 core = 0.1 vCPU = 0.1 AWS vCPU = 0.1 GCP Core.
- 8000m = 8 cores = 8 vCPUs

# Configure Quality of Service for Pods (VVI)

- When Kubernetes creates a Pod it assigns one of these QoS classes to the Pod:
    - Guaranteed
    - Burstable
    - BestEffort
- For a Pod to be given a QoS class of Guaranteed:
    - Every Container in the Pod must have a memory limit and a memory request.
    - For every Container in the Pod, the memory limit must equal the memory request.
    - Every Container in the Pod must have a CPU limit and a CPU request.
    - For every Container in the Pod, the CPU limit must equal the CPU request.

```
spec:
  containers:
    ...
    resources:
      limits:
        cpu: 700m
        memory: 200Mi
      requests:
        cpu: 700m
        memory: 200Mi
    ...
status: -------------------------------------> define quos
  qosClass: Guaranteed
```
- A Pod is given a QoS class of Burstable if:

  - The Pod does not meet the criteria for QoS class Guaranteed.
  At least one Container in the Pod has a memory or CPU request or limit.
  Here is the configuration file for a Pod that has one Container. The Container has a memory limit of 200 MiB and a memory request of 100 MiB.

```
apiVersion: v1
kind: Pod
metadata:
  name: qos-demo-2
  namespace: qos-example
spec:
  containers:
  - name: qos-demo-2-ctr
    image: nginx
    resources:
      limits:
        memory: "200Mi"
      requests:
        memory: "100Mi"
```
- kubectl apply -f https://k8s.io/examples/pods/qos/qos-pod-2.yaml --namespace=qos-example
- kubectl get pod qos-demo-2 --namespace=qos-example --output=yaml
```
status:
  qosClass: Burstable
```
- For a Pod to be given a QoS class of BestEffort, the Containers in the Pod must not have any memory or CPU limits or requests.

- https://kubernetes.io/docs/concepts/storage/projected-volumes/ `VVI - projected volumes`

- How would you approach hot reloading of values defined by a ConfigMap consumed by an application running in Pod?
Changes to environment variables are only reflected if the Pod is restarted. Alternatively, you can mount a ConfigMap as file and poll changes from the mounted file periodically, however, it requires the application to build in the logic.